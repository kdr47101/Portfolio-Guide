# KDR - Data Project Portfolio

Welcome to my data portfolio! Here we have a catalogue of my more notable projects.
# Table of Contents

- [Data Analytics & SQL](#data-analytics-&-sql)
- [Machine Learning & Modeling](#machine-learning-&-modeling)
- [Data Engineering & Pipelines](#data-engineering-&-pipelines)
- [Learning Notes & Other](#learning-notes-&-other)

---

# Data Analytics & SQL

| Project Link | Area | Tools | Project Description |
|--------------|------|-------|---------------------|
| [Supply Chain Optimization](https://github.com/kdr47101/Supply-Chain-Optimization) | Data analysis, data cleaning, exploratory data analysis, data visualization, supply chain analytics | Python, Jupyter Notebooks, Power BI | An end-to-end analysis of logistics data to optimize shipment efficiency and improve supply-chain visibility. Work includes cleaning and exploring the dataset, plus a Tableau dashboard highlighting top routes, delay drivers, supplier performance trends, and peak shipment periods |
| [UTSC SDG Data Challenge Submission](https://github.com/kdr47101/UTSC-SDG-Data-Challenge) | Data analysis, data cleaning, data transformation, cross validaiton, multiple linear regression | Python (numpy, seaborn, pandas, matplotlib), Power BI | My teams submission to the UTSC SDG Data Challenge. Tested if countries can grow real GDP per capita (SDG 8.1.1) while holding/reducing total GHG emissions (SDG 13.2.2). Built a Î² ratio and multiple regression model that explained ~50% of variance explained by industry share, resource rents, and FDI.|
| [Toronto Bikeshare Demand Forecasting](https://github.com/kdr47101/Bikeshare-Demand-Forecasting) (Note this is a work in progress) | Data analysis, data cleaning, data transformation, time-series analysis | Python (numpy, pandas, prophet), Toronto Data Portal API, meteostat API | 2025 bikeshare demand forecasting by station using bike ridership data and bike station data (from Toronto Open Data Portal API's) and historical weather data (from meteostat API. OBJECTIVE: Identify which of the 1942 unique stations have forecasted demand that significantly exceed their current capacity (and hence, would benefit from upsizing).  |
| [Complaint-Driven Product Idea Miner](https://github.com/kdr47101/Complaint-Driven-Product-Idea-Miner) | Data mining, natural language processing, text analysis, product research | Python (Streamlit), Reddit API (PRAW), Google Gemini API, MongoDB Atlas | A Streamlit application that discovers product opportunities by mining Reddit for user complaints. Users enter a keyword/domain, and the app uses Google Gemini to identify relevant subreddits, fetches top posts, filters comments for complaint language, and extracts actionable product ideas with AI-assigned relevance scores (0-100). Features include customizable search parameters, ranked results table with upvotes and relevance scores, and CSV export functionality for further analysis. |
| [8-Week SQL Challenges](https://github.com/kdr47101/8-Week-SQL-Challenge) | Data analysis, data cleaning, data transformation | SQL | This repo serves as the solution for the 8 case studies from the [8WeekSQLChallenge](https://8weeksqlchallenge.com/). It showcases my ability to tackle various SQL challenges and demonstrates my proficiency in SQL query writing and problem-solving skills. |

---

# Machine Learning & Modeling

| Project Link | Tools | Project Description |
|--------------|------------------|----------------------|
| [AML ML Competition Submission](https://github.com/kdr47101/IMI-Big-Data-and-AI-comp-submission) | Python (pandas, scikit-learn, logging), Jupyter Notebooks, Docker, Bash | End-to-end AML transaction analytics pipeline: cleans multi-source bank data, runs IsolationForest anomaly detection, logs results, and exports per-channel anomalies and visualizations for downstream review. |
| [Loan Payback Prediction](https://github.com/kdr47101/Kaggle-Competition-Predicting-Loan-Payback) | Python (pandas, numpy, scikit-learn, XGBoost, LightGBM, Optuna), Jupyter Notebooks | Kaggle competition predicting loan repayment probability using LightGBM. Applied target encoding with smoothing for high-cardinality categoricals and label encoding for remaining features. Optimized hyperparameters using Optuna across 200 trials with 10-fold stratified cross-validation to prevent data leakage and maximize AUC performance. |

---

# Data Engineering & Pipelines

| Project Link | Tools | Project Description |
|--------------|-------|----------------|
| [Uber Taxi](https://github.com/kdr47101/Uber-Data-Engineering-Project) | Python, GCP (Storage, Compute Engine, BigQuery), Mage, Looker Studio | Developed and implemented an end-to-end ETL pipeline for processing NYC Trip Record data. The pipeline encompassed extracting raw data, performing data transformation using Python, applying fact and dimensional data modelling techniques, orchestrating the pipeline on Mage, and ultimately creating a dashboard using Looker Studio. |

---

# Learning Notes & Other

| Project Link | Tools | Project Description |
|--------------|-------|---------------------|
| [ISLP - Personal Solutions](https://github.com/kdr47101/ISLP-Personal-Solutions) | Data analysis, regression, classification, resampling, regularization, non-linear models, tree-based methods, SVM, unsupervised learning | Python (NumPy, pandas, scikit-learn, statsmodels, matplotlib), Jupyter Notebooks |  Personal, reproducible solutions to ISLP labs/exercises with EDA, modeling, and evaluation notebooks. |

---
